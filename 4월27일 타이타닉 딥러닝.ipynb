{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ecda8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc01488",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv(\"C:/Users/TFG155/Desktop/인공지능개론/AI-class-main/titanic.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968f94b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "...               ...     ...   \n",
       "887                 0       2   \n",
       "888                 1       1   \n",
       "889                 0       3   \n",
       "890                 1       1   \n",
       "891                 0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "...                                                        ...     ...   ...   \n",
       "887                                      Montvila, Rev. Juozas    male  27.0   \n",
       "888                               Graham, Miss. Margaret Edith  female  19.0   \n",
       "889                   Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN   \n",
       "890                                      Behr, Mr. Karl Howell    male  26.0   \n",
       "891                                        Dooley, Mr. Patrick    male  32.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  \n",
       "...            ...    ...               ...      ...   ...      ...  \n",
       "887              0      0            211536  13.0000   NaN        S  \n",
       "888              0      0            112053  30.0000   B42        S  \n",
       "889              1      2        W./C. 6607  23.4500   NaN        S  \n",
       "890              0      0            111369  30.0000  C148        C  \n",
       "891              0      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d506a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "features['Sex'] = le.fit_transform(features['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4cf08f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>714 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  Sex   Age  SibSp  Parch     Fare\n",
       "PassengerId                                                    \n",
       "1                   0       3    1  22.0      1      0   7.2500\n",
       "2                   1       1    0  38.0      1      0  71.2833\n",
       "3                   1       3    0  26.0      0      0   7.9250\n",
       "4                   1       1    0  35.0      1      0  53.1000\n",
       "5                   0       3    1  35.0      0      0   8.0500\n",
       "...               ...     ...  ...   ...    ...    ...      ...\n",
       "886                 0       3    0  39.0      0      5  29.1250\n",
       "887                 0       2    1  27.0      0      0  13.0000\n",
       "888                 1       1    0  19.0      0      0  30.0000\n",
       "890                 1       1    1  26.0      0      0  30.0000\n",
       "891                 0       3    1  32.0      0      0   7.7500\n",
       "\n",
       "[714 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = features\n",
    "data = data.drop(columns=['Name', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "data = data.dropna(axis=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "583c0407",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,1:7].values\n",
    "y = data.iloc[:,0].values\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder =  LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "\n",
    "Y = pd.get_dummies(y1).values\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "088a5eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.    ,  1.    , 22.    ,  1.    ,  0.    ,  7.25  ],\n",
       "       [ 1.    ,  0.    , 38.    ,  1.    ,  0.    , 71.2833],\n",
       "       [ 3.    ,  0.    , 26.    ,  0.    ,  0.    ,  7.925 ],\n",
       "       ...,\n",
       "       [ 1.    ,  0.    , 19.    ,  0.    ,  0.    , 30.    ],\n",
       "       [ 1.    ,  1.    , 26.    ,  0.    ,  0.    , 30.    ],\n",
       "       [ 3.    ,  1.    , 32.    ,  0.    ,  0.    ,  7.75  ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a8625cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       ...,\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dda7d2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 100)               700       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 80)                8080      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 60)                4860      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 122       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,762\n",
      "Trainable params: 13,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD,Adam\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100,input_shape=(6,),activation='relu'))\n",
    "model.add(Dense(80,activation='relu'))\n",
    "model.add(Dense(60,activation='relu'))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(Adam(lr=0.04),'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9e5ec3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 1s 16ms/step - loss: 3.0077 - accuracy: 0.5622 - val_loss: 0.6567 - val_accuracy: 0.6853\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6351 - accuracy: 0.6848 - val_loss: 0.6670 - val_accuracy: 0.6503\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5874 - accuracy: 0.6918 - val_loss: 0.6132 - val_accuracy: 0.6503\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5745 - accuracy: 0.6918 - val_loss: 0.6060 - val_accuracy: 0.6573\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5559 - accuracy: 0.7040 - val_loss: 0.5654 - val_accuracy: 0.7343\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5636 - accuracy: 0.6900 - val_loss: 0.5490 - val_accuracy: 0.7552\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5376 - accuracy: 0.7531 - val_loss: 0.6248 - val_accuracy: 0.5874\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5626 - accuracy: 0.7461 - val_loss: 0.6531 - val_accuracy: 0.6713\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5361 - accuracy: 0.7601 - val_loss: 0.5708 - val_accuracy: 0.7483\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5173 - accuracy: 0.7443 - val_loss: 0.5562 - val_accuracy: 0.7063\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7426 - val_loss: 0.5385 - val_accuracy: 0.7762\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5156 - accuracy: 0.7706 - val_loss: 0.5230 - val_accuracy: 0.7762\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5276 - accuracy: 0.7723 - val_loss: 0.5054 - val_accuracy: 0.7692\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5198 - accuracy: 0.7776 - val_loss: 0.5523 - val_accuracy: 0.7832\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5589 - accuracy: 0.7461 - val_loss: 0.5900 - val_accuracy: 0.7832\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5248 - accuracy: 0.7583 - val_loss: 0.6741 - val_accuracy: 0.7762\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.7758 - val_loss: 0.5080 - val_accuracy: 0.7552\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7811 - val_loss: 0.5330 - val_accuracy: 0.7692\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.8161 - val_loss: 0.5162 - val_accuracy: 0.7902\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4837 - accuracy: 0.7881 - val_loss: 0.5179 - val_accuracy: 0.7622\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4968 - accuracy: 0.7846 - val_loss: 0.5703 - val_accuracy: 0.7902\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4872 - accuracy: 0.7828 - val_loss: 0.4767 - val_accuracy: 0.7972\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4783 - accuracy: 0.7951 - val_loss: 0.5148 - val_accuracy: 0.7762\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4998 - accuracy: 0.8021 - val_loss: 0.5462 - val_accuracy: 0.7483\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4693 - accuracy: 0.8039 - val_loss: 0.5780 - val_accuracy: 0.7622\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4900 - accuracy: 0.7968 - val_loss: 0.5020 - val_accuracy: 0.7692\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4895 - accuracy: 0.7828 - val_loss: 0.5234 - val_accuracy: 0.7552\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7881 - val_loss: 0.5382 - val_accuracy: 0.7552\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7828 - val_loss: 0.5103 - val_accuracy: 0.7622\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4674 - accuracy: 0.7846 - val_loss: 0.4919 - val_accuracy: 0.7972\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4745 - accuracy: 0.8004 - val_loss: 0.4895 - val_accuracy: 0.7622\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4476 - accuracy: 0.8039 - val_loss: 0.5892 - val_accuracy: 0.7273\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4908 - accuracy: 0.7898 - val_loss: 0.5519 - val_accuracy: 0.7762\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5027 - accuracy: 0.7986 - val_loss: 0.4847 - val_accuracy: 0.7552\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7793 - val_loss: 0.4479 - val_accuracy: 0.8112\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.8074 - val_loss: 0.5477 - val_accuracy: 0.7762\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.8039 - val_loss: 0.5523 - val_accuracy: 0.7622\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4856 - accuracy: 0.8056 - val_loss: 0.4749 - val_accuracy: 0.8252\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.7846 - val_loss: 0.6402 - val_accuracy: 0.8182\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.8144 - val_loss: 0.4845 - val_accuracy: 0.7483\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.8126 - val_loss: 0.4973 - val_accuracy: 0.7832\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.8091 - val_loss: 0.5102 - val_accuracy: 0.8042\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.7951 - val_loss: 0.6068 - val_accuracy: 0.7133\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.5143 - accuracy: 0.7933 - val_loss: 0.5006 - val_accuracy: 0.7622\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4744 - accuracy: 0.7951 - val_loss: 0.4824 - val_accuracy: 0.7762\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.8039 - val_loss: 0.5159 - val_accuracy: 0.8252\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.8179 - val_loss: 0.4595 - val_accuracy: 0.7762\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8179 - val_loss: 0.4736 - val_accuracy: 0.7832\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.8021 - val_loss: 0.4937 - val_accuracy: 0.7692\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.8056 - val_loss: 0.4644 - val_accuracy: 0.8182\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7898 - val_loss: 0.4616 - val_accuracy: 0.7902\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.8021 - val_loss: 0.5036 - val_accuracy: 0.7483\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.8109 - val_loss: 0.5048 - val_accuracy: 0.7692\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.7986 - val_loss: 0.4888 - val_accuracy: 0.7692\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4276 - accuracy: 0.8214 - val_loss: 0.4558 - val_accuracy: 0.7762\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.8074 - val_loss: 0.4935 - val_accuracy: 0.7762\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7951 - val_loss: 0.4833 - val_accuracy: 0.7832\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4311 - accuracy: 0.8179 - val_loss: 0.5079 - val_accuracy: 0.7622\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4303 - accuracy: 0.8074 - val_loss: 0.4655 - val_accuracy: 0.8252\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.8091 - val_loss: 0.5377 - val_accuracy: 0.7692\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4954 - accuracy: 0.7776 - val_loss: 0.5075 - val_accuracy: 0.7832\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4731 - accuracy: 0.7916 - val_loss: 0.5328 - val_accuracy: 0.7483\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.8056 - val_loss: 0.5905 - val_accuracy: 0.7762\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4698 - accuracy: 0.7793 - val_loss: 0.4497 - val_accuracy: 0.8042\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4211 - accuracy: 0.8126 - val_loss: 0.4529 - val_accuracy: 0.7902\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4372 - accuracy: 0.8249 - val_loss: 0.4893 - val_accuracy: 0.7273\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.5131 - accuracy: 0.7828 - val_loss: 0.4572 - val_accuracy: 0.7972\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.8074 - val_loss: 0.4800 - val_accuracy: 0.7832\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4376 - accuracy: 0.8091 - val_loss: 0.5677 - val_accuracy: 0.7343\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5694 - accuracy: 0.7828 - val_loss: 0.5656 - val_accuracy: 0.8042\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5340 - accuracy: 0.7461 - val_loss: 0.6364 - val_accuracy: 0.7413\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4905 - accuracy: 0.7898 - val_loss: 0.6426 - val_accuracy: 0.6993\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5457 - accuracy: 0.7828 - val_loss: 0.5322 - val_accuracy: 0.7692\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5082 - accuracy: 0.7933 - val_loss: 0.4607 - val_accuracy: 0.7902\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4527 - accuracy: 0.7898 - val_loss: 0.5401 - val_accuracy: 0.8042\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4700 - accuracy: 0.7968 - val_loss: 0.5433 - val_accuracy: 0.7832\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5028 - accuracy: 0.7898 - val_loss: 0.4819 - val_accuracy: 0.7832\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.8004 - val_loss: 0.4654 - val_accuracy: 0.7762\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8196 - val_loss: 0.4691 - val_accuracy: 0.8042\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.8126 - val_loss: 0.4763 - val_accuracy: 0.7622\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8039 - val_loss: 0.4694 - val_accuracy: 0.7762\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.8091 - val_loss: 0.4850 - val_accuracy: 0.8042\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.8144 - val_loss: 0.4766 - val_accuracy: 0.8182\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.8144 - val_loss: 0.4584 - val_accuracy: 0.7902\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.8179 - val_loss: 0.6158 - val_accuracy: 0.7692\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4707 - accuracy: 0.8021 - val_loss: 0.4972 - val_accuracy: 0.7622\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.8004 - val_loss: 0.4836 - val_accuracy: 0.7832\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.8091 - val_loss: 0.4884 - val_accuracy: 0.7762\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.8004 - val_loss: 0.4491 - val_accuracy: 0.7622\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7986 - val_loss: 0.4710 - val_accuracy: 0.7622\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.8091 - val_loss: 0.5461 - val_accuracy: 0.7552\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8179 - val_loss: 0.4764 - val_accuracy: 0.7972\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7951 - val_loss: 0.5535 - val_accuracy: 0.7413\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4796 - accuracy: 0.8144 - val_loss: 0.5231 - val_accuracy: 0.7902\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.8109 - val_loss: 0.4699 - val_accuracy: 0.7902\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.8214 - val_loss: 0.4827 - val_accuracy: 0.8042\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4538 - accuracy: 0.8056 - val_loss: 0.4954 - val_accuracy: 0.7972\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4595 - accuracy: 0.8021 - val_loss: 0.4786 - val_accuracy: 0.7832\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4403 - accuracy: 0.8144 - val_loss: 0.4499 - val_accuracy: 0.7972\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.8161 - val_loss: 0.4531 - val_accuracy: 0.8322\n",
      "5/5 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "model_history=model.fit(x=X_train, y=y_train, epochs=100, batch_size=32,validation_data= (X_test,y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ba37a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86        79\n",
      "           1       0.90      0.70      0.79        64\n",
      "\n",
      "    accuracy                           0.83       143\n",
      "   macro avg       0.85      0.82      0.82       143\n",
      "weighted avg       0.84      0.83      0.83       143\n",
      "\n",
      "[[74  5]\n",
      " [19 45]]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the predicted values\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test_class,y_pred_class))\n",
    "print(confusion_matrix(y_test_class,y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
