{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2     3      4     5      6\n",
       "0     vhigh  vhigh      2     2  small   low  unacc\n",
       "1     vhigh  vhigh      2     2  small   med  unacc\n",
       "2     vhigh  vhigh      2     2  small  high  unacc\n",
       "3     vhigh  vhigh      2     2    med   low  unacc\n",
       "4     vhigh  vhigh      2     2    med   med  unacc\n",
       "...     ...    ...    ...   ...    ...   ...    ...\n",
       "1723    low    low  5more  more    med   med   good\n",
       "1724    low    low  5more  more    med  high  vgood\n",
       "1725    low    low  5more  more    big   low  unacc\n",
       "1726    low    low  5more  more    big   med   good\n",
       "1727    low    low  5more  more    big  high  vgood\n",
       "\n",
       "[1728 rows x 7 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "dataset = pd.read_csv(\"C:/Users/TFG155/Desktop/인공지능개론/중간고사 데이터/car.data\",index_col = None, header=None)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2     3      4     5      6\n",
       "0     vhigh  vhigh      2     2  small   low  unacc\n",
       "1     vhigh  vhigh      2     2  small   med  unacc\n",
       "2     vhigh  vhigh      2     2  small  high  unacc\n",
       "3     vhigh  vhigh      2     2    med   low  unacc\n",
       "4     vhigh  vhigh      2     2    med   med  unacc\n",
       "...     ...    ...    ...   ...    ...   ...    ...\n",
       "1723    low    low  5more  more    med   med   good\n",
       "1724    low    low  5more  more    med  high  vgood\n",
       "1725    low    low  5more  more    big   low  unacc\n",
       "1726    low    low  5more  more    big   med   good\n",
       "1727    low    low  5more  more    big  high  vgood\n",
       "\n",
       "[1728 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = dataset[6])\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "for i in dataset.columns:\n",
    "    dataset[i] = le.fit_transform(dataset[i])\n",
    "\n",
    "X =dataset.iloc[:, [0,1,2,3,4,5]].values\n",
    "y =dataset.loc[:, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder =  LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "\n",
    "Y = pd.get_dummies(y1).values\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 0, 0, 2, 1],\n",
       "       [3, 3, 0, 0, 2, 2],\n",
       "       [3, 3, 0, 0, 2, 0],\n",
       "       ...,\n",
       "       [1, 1, 3, 2, 0, 1],\n",
       "       [1, 1, 3, 2, 0, 2],\n",
       "       [1, 1, 3, 2, 0, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 5, 64)             192       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 320)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 50)                16050     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,293\n",
      "Trainable params: 16,293\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import SGD,Adam\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(6, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1)) \n",
    "model.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mse'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 1s 5ms/step - loss: 0.1953 - mse: 0.1953 - val_loss: 0.1898 - val_mse: 0.1898\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1911 - mse: 0.1911 - val_loss: 0.1889 - val_mse: 0.1889\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1898 - mse: 0.1898 - val_loss: 0.1918 - val_mse: 0.1918\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1892 - mse: 0.1892 - val_loss: 0.1882 - val_mse: 0.1882\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1888 - mse: 0.1888 - val_loss: 0.1883 - val_mse: 0.1883\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1884 - mse: 0.1884 - val_loss: 0.1887 - val_mse: 0.1887\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1883 - mse: 0.1883 - val_loss: 0.1877 - val_mse: 0.1877\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1882 - mse: 0.1882 - val_loss: 0.1881 - val_mse: 0.1881\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1880 - mse: 0.1880 - val_loss: 0.1880 - val_mse: 0.1880\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1880 - mse: 0.1880 - val_loss: 0.1879 - val_mse: 0.1879\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1879 - mse: 0.1879 - val_loss: 0.1877 - val_mse: 0.1877\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1879 - mse: 0.1879 - val_loss: 0.1877 - val_mse: 0.1877\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1879 - mse: 0.1879 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1878 - mse: 0.1878 - val_loss: 0.1880 - val_mse: 0.1880\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1877 - mse: 0.1877 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.1878 - mse: 0.1878 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1877 - mse: 0.1877 - val_loss: 0.1877 - val_mse: 0.1877\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1877 - mse: 0.1877 - val_loss: 0.1879 - val_mse: 0.1879\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1877 - mse: 0.1877 - val_loss: 0.1878 - val_mse: 0.1878\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1877 - mse: 0.1877 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1877 - mse: 0.1877 - val_loss: 0.1878 - val_mse: 0.1878\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1877 - mse: 0.1877 - val_loss: 0.1878 - val_mse: 0.1878\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1877 - mse: 0.1877 - val_loss: 0.1879 - val_mse: 0.1879\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1878 - val_mse: 0.1878\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 26/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1878 - val_mse: 0.1878\n",
      "Epoch 27/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 28/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1877 - val_mse: 0.1877\n",
      "Epoch 29/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1878 - val_mse: 0.1878\n",
      "Epoch 30/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 31/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1878 - val_mse: 0.1878\n",
      "Epoch 32/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 33/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1877 - val_mse: 0.1877\n",
      "Epoch 34/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 35/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 36/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 37/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 38/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 39/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1877 - val_mse: 0.1877\n",
      "Epoch 40/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 41/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 42/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 43/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 44/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 45/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1876 - mse: 0.1876 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 46/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 47/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 48/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 49/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 50/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 51/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 52/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 53/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 54/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 55/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 56/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 57/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 58/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 59/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 60/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 61/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 62/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1877 - val_mse: 0.1877\n",
      "Epoch 63/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 64/100\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 65/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1876 - val_mse: 0.1876\n",
      "Epoch 66/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 67/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 68/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 69/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 70/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 71/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 72/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 73/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 74/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 75/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 76/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 77/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 78/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 79/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 80/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 81/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 82/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 83/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 84/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 85/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 86/100\n",
      "44/44 [==============================] - 0s 4ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 87/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 88/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 89/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 90/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 91/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 92/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 93/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 94/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 95/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 96/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 97/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 98/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 99/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 100/100\n",
      "44/44 [==============================] - 0s 3ms/step - loss: 0.1875 - mse: 0.1875 - val_loss: 0.1875 - val_mse: 0.1875\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "history = model.fit(X_train, y_train, epochs = N_EPOCHS, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.1875 - mse: 0.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18750883638858795, 0.18750883638858795]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
