{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87524</td>\n",
       "      <td>442.246011</td>\n",
       "      <td>253.291155</td>\n",
       "      <td>0.819738</td>\n",
       "      <td>90546</td>\n",
       "      <td>0.758651</td>\n",
       "      <td>1184.040</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75166</td>\n",
       "      <td>406.690687</td>\n",
       "      <td>243.032436</td>\n",
       "      <td>0.801805</td>\n",
       "      <td>78789</td>\n",
       "      <td>0.684130</td>\n",
       "      <td>1121.786</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90856</td>\n",
       "      <td>442.267048</td>\n",
       "      <td>266.328318</td>\n",
       "      <td>0.798354</td>\n",
       "      <td>93717</td>\n",
       "      <td>0.637613</td>\n",
       "      <td>1208.575</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45928</td>\n",
       "      <td>286.540559</td>\n",
       "      <td>208.760042</td>\n",
       "      <td>0.684989</td>\n",
       "      <td>47336</td>\n",
       "      <td>0.699599</td>\n",
       "      <td>844.162</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79408</td>\n",
       "      <td>352.190770</td>\n",
       "      <td>290.827533</td>\n",
       "      <td>0.564011</td>\n",
       "      <td>81463</td>\n",
       "      <td>0.792772</td>\n",
       "      <td>1073.251</td>\n",
       "      <td>Kecimen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>83248</td>\n",
       "      <td>430.077308</td>\n",
       "      <td>247.838695</td>\n",
       "      <td>0.817263</td>\n",
       "      <td>85839</td>\n",
       "      <td>0.668793</td>\n",
       "      <td>1129.072</td>\n",
       "      <td>Besni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>87350</td>\n",
       "      <td>440.735698</td>\n",
       "      <td>259.293149</td>\n",
       "      <td>0.808629</td>\n",
       "      <td>90899</td>\n",
       "      <td>0.636476</td>\n",
       "      <td>1214.252</td>\n",
       "      <td>Besni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>99657</td>\n",
       "      <td>431.706981</td>\n",
       "      <td>298.837323</td>\n",
       "      <td>0.721684</td>\n",
       "      <td>106264</td>\n",
       "      <td>0.741099</td>\n",
       "      <td>1292.828</td>\n",
       "      <td>Besni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>93523</td>\n",
       "      <td>476.344094</td>\n",
       "      <td>254.176054</td>\n",
       "      <td>0.845739</td>\n",
       "      <td>97653</td>\n",
       "      <td>0.658798</td>\n",
       "      <td>1258.548</td>\n",
       "      <td>Besni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>85609</td>\n",
       "      <td>512.081774</td>\n",
       "      <td>215.271976</td>\n",
       "      <td>0.907345</td>\n",
       "      <td>89197</td>\n",
       "      <td>0.632020</td>\n",
       "      <td>1272.862</td>\n",
       "      <td>Besni</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>900 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Area  MajorAxisLength  MinorAxisLength  Eccentricity  ConvexArea  \\\n",
       "0    87524       442.246011       253.291155      0.819738       90546   \n",
       "1    75166       406.690687       243.032436      0.801805       78789   \n",
       "2    90856       442.267048       266.328318      0.798354       93717   \n",
       "3    45928       286.540559       208.760042      0.684989       47336   \n",
       "4    79408       352.190770       290.827533      0.564011       81463   \n",
       "..     ...              ...              ...           ...         ...   \n",
       "895  83248       430.077308       247.838695      0.817263       85839   \n",
       "896  87350       440.735698       259.293149      0.808629       90899   \n",
       "897  99657       431.706981       298.837323      0.721684      106264   \n",
       "898  93523       476.344094       254.176054      0.845739       97653   \n",
       "899  85609       512.081774       215.271976      0.907345       89197   \n",
       "\n",
       "       Extent  Perimeter    Class  \n",
       "0    0.758651   1184.040  Kecimen  \n",
       "1    0.684130   1121.786  Kecimen  \n",
       "2    0.637613   1208.575  Kecimen  \n",
       "3    0.699599    844.162  Kecimen  \n",
       "4    0.792772   1073.251  Kecimen  \n",
       "..        ...        ...      ...  \n",
       "895  0.668793   1129.072    Besni  \n",
       "896  0.636476   1214.252    Besni  \n",
       "897  0.741099   1292.828    Besni  \n",
       "898  0.658798   1258.548    Besni  \n",
       "899  0.632020   1272.862    Besni  \n",
       "\n",
       "[900 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "features = pd.read_csv(\"C:/Users/TFG155/Desktop/인공지능개론/데이터/Raisin_Dataset.csv\", index_col = None, header = 0)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Area               0\n",
       "MajorAxisLength    0\n",
       "MinorAxisLength    0\n",
       "Eccentricity       0\n",
       "ConvexArea         0\n",
       "Extent             0\n",
       "Perimeter          0\n",
       "Class              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = features['Class'])\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "for i in features.columns:\n",
    "    features[i] = le.fit_transform(features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features.iloc[:,0:7].values\n",
    "y = features.iloc[:,7].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder =  LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "\n",
    "Y = pd.get_dummies(y1).values\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 100)               800       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 80)                8080      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 60)                4860      \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 2)                 122       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,862\n",
      "Trainable params: 13,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TFG155\\anaconda3\\lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD,Adam\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100,input_shape=(7,),activation='relu'))\n",
    "model.add(Dense(80,activation='relu'))\n",
    "model.add(Dense(60,activation='relu'))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(Adam(lr=0.04),'binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 13ms/step - loss: 33.5647 - accuracy: 0.6097 - val_loss: 0.7010 - val_accuracy: 0.6722\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.5846 - accuracy: 0.7319 - val_loss: 0.4019 - val_accuracy: 0.8278\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.8236 - val_loss: 0.4216 - val_accuracy: 0.8556\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8167 - val_loss: 0.4983 - val_accuracy: 0.8111\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7972 - val_loss: 0.3588 - val_accuracy: 0.8278\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8375 - val_loss: 0.3524 - val_accuracy: 0.8389\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8403 - val_loss: 0.3903 - val_accuracy: 0.8889\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3858 - accuracy: 0.8417 - val_loss: 0.3307 - val_accuracy: 0.8833\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3822 - accuracy: 0.8486 - val_loss: 0.3319 - val_accuracy: 0.8556\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.8361 - val_loss: 0.3438 - val_accuracy: 0.8889\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8361 - val_loss: 0.4142 - val_accuracy: 0.8722\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3954 - accuracy: 0.8194 - val_loss: 0.3486 - val_accuracy: 0.8833\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3666 - accuracy: 0.8500 - val_loss: 0.3224 - val_accuracy: 0.8778\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3565 - accuracy: 0.8458 - val_loss: 0.3625 - val_accuracy: 0.8833\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3647 - accuracy: 0.8472 - val_loss: 0.3266 - val_accuracy: 0.8500\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8319 - val_loss: 0.3128 - val_accuracy: 0.8778\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8375 - val_loss: 0.3245 - val_accuracy: 0.8889\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8264 - val_loss: 0.3818 - val_accuracy: 0.8222\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8458 - val_loss: 0.3161 - val_accuracy: 0.8667\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8542 - val_loss: 0.3164 - val_accuracy: 0.9000\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3723 - accuracy: 0.8458 - val_loss: 0.3143 - val_accuracy: 0.8944\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3864 - accuracy: 0.8264 - val_loss: 0.3168 - val_accuracy: 0.9000\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8500 - val_loss: 0.3108 - val_accuracy: 0.8667\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8403 - val_loss: 0.3049 - val_accuracy: 0.8722\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3752 - accuracy: 0.8528 - val_loss: 0.3064 - val_accuracy: 0.8722\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8569 - val_loss: 0.3145 - val_accuracy: 0.9111\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3481 - accuracy: 0.8611 - val_loss: 0.3106 - val_accuracy: 0.9111\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8431 - val_loss: 0.3108 - val_accuracy: 0.8667\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3640 - accuracy: 0.8597 - val_loss: 0.3132 - val_accuracy: 0.8667\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3567 - accuracy: 0.8583 - val_loss: 0.3222 - val_accuracy: 0.8667\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.8583 - val_loss: 0.3005 - val_accuracy: 0.8944\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3690 - accuracy: 0.8556 - val_loss: 0.3422 - val_accuracy: 0.8944\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3480 - accuracy: 0.8500 - val_loss: 0.3109 - val_accuracy: 0.9167\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8583 - val_loss: 0.3064 - val_accuracy: 0.8667\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3753 - accuracy: 0.8431 - val_loss: 0.4151 - val_accuracy: 0.8389\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3781 - accuracy: 0.8472 - val_loss: 0.3489 - val_accuracy: 0.9056\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8181 - val_loss: 0.4246 - val_accuracy: 0.8167\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3740 - accuracy: 0.8347 - val_loss: 0.4658 - val_accuracy: 0.8278\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7931 - val_loss: 0.3472 - val_accuracy: 0.8500\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8486 - val_loss: 0.3228 - val_accuracy: 0.8833\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3475 - accuracy: 0.8542 - val_loss: 0.3246 - val_accuracy: 0.8500\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3690 - accuracy: 0.8361 - val_loss: 0.3168 - val_accuracy: 0.8556\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.4577 - accuracy: 0.8167 - val_loss: 0.5012 - val_accuracy: 0.7389\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8250 - val_loss: 0.3200 - val_accuracy: 0.8722\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3469 - accuracy: 0.8528 - val_loss: 0.3061 - val_accuracy: 0.9000\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.8514 - val_loss: 0.2996 - val_accuracy: 0.8944\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8625 - val_loss: 0.3733 - val_accuracy: 0.8611\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3529 - accuracy: 0.8611 - val_loss: 0.2976 - val_accuracy: 0.9056\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8319 - val_loss: 0.3375 - val_accuracy: 0.8944\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3530 - accuracy: 0.8472 - val_loss: 0.3176 - val_accuracy: 0.9056\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3879 - accuracy: 0.8347 - val_loss: 0.4007 - val_accuracy: 0.8500\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8472 - val_loss: 0.3038 - val_accuracy: 0.8944\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3305 - accuracy: 0.8625 - val_loss: 0.3024 - val_accuracy: 0.8611\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8597 - val_loss: 0.3004 - val_accuracy: 0.9111\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8486 - val_loss: 0.3065 - val_accuracy: 0.8556\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3546 - accuracy: 0.8528 - val_loss: 0.3940 - val_accuracy: 0.8556\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3683 - accuracy: 0.8319 - val_loss: 0.2937 - val_accuracy: 0.9056\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8153 - val_loss: 0.3249 - val_accuracy: 0.8722\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8375 - val_loss: 0.3015 - val_accuracy: 0.8722\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3460 - accuracy: 0.8486 - val_loss: 0.3082 - val_accuracy: 0.9056\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3330 - accuracy: 0.8569 - val_loss: 0.3011 - val_accuracy: 0.8722\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3684 - accuracy: 0.8431 - val_loss: 0.3167 - val_accuracy: 0.8667\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3320 - accuracy: 0.8583 - val_loss: 0.2999 - val_accuracy: 0.9056\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3881 - accuracy: 0.8375 - val_loss: 0.2885 - val_accuracy: 0.8833\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3641 - accuracy: 0.8444 - val_loss: 0.3055 - val_accuracy: 0.8667\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3316 - accuracy: 0.8569 - val_loss: 0.2870 - val_accuracy: 0.8944\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3496 - accuracy: 0.8681 - val_loss: 0.3070 - val_accuracy: 0.9111\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3477 - accuracy: 0.8472 - val_loss: 0.2998 - val_accuracy: 0.8722\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3446 - accuracy: 0.8625 - val_loss: 0.3033 - val_accuracy: 0.9111\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8597 - val_loss: 0.4102 - val_accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3924 - accuracy: 0.8319 - val_loss: 0.4298 - val_accuracy: 0.8444\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.8500 - val_loss: 0.3006 - val_accuracy: 0.9222\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8625 - val_loss: 0.3738 - val_accuracy: 0.8611\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3470 - accuracy: 0.8556 - val_loss: 0.2877 - val_accuracy: 0.9000\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8528 - val_loss: 0.3060 - val_accuracy: 0.8722\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3429 - accuracy: 0.8639 - val_loss: 0.3148 - val_accuracy: 0.8611\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8681 - val_loss: 0.3153 - val_accuracy: 0.8667\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3514 - accuracy: 0.8444 - val_loss: 0.3144 - val_accuracy: 0.8667\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3438 - accuracy: 0.8597 - val_loss: 0.2959 - val_accuracy: 0.8611\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4116 - accuracy: 0.8236 - val_loss: 0.2943 - val_accuracy: 0.8611\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3326 - accuracy: 0.8611 - val_loss: 0.2833 - val_accuracy: 0.8889\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3322 - accuracy: 0.8597 - val_loss: 0.2815 - val_accuracy: 0.9000\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3222 - accuracy: 0.8653 - val_loss: 0.2797 - val_accuracy: 0.8833\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8556 - val_loss: 0.2821 - val_accuracy: 0.8833\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3304 - accuracy: 0.8611 - val_loss: 0.2932 - val_accuracy: 0.8833\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8556 - val_loss: 0.3053 - val_accuracy: 0.9167\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3381 - accuracy: 0.8500 - val_loss: 0.3138 - val_accuracy: 0.9056\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3249 - accuracy: 0.8694 - val_loss: 0.2885 - val_accuracy: 0.9000\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 6ms/step - loss: 0.3290 - accuracy: 0.8583 - val_loss: 0.3941 - val_accuracy: 0.8500\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.4106 - accuracy: 0.8361 - val_loss: 0.5332 - val_accuracy: 0.6611\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8306 - val_loss: 0.2996 - val_accuracy: 0.9000\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8639 - val_loss: 0.3239 - val_accuracy: 0.8611\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3557 - accuracy: 0.8583 - val_loss: 0.4316 - val_accuracy: 0.8333\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8528 - val_loss: 0.2969 - val_accuracy: 0.9056\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3290 - accuracy: 0.8694 - val_loss: 0.3083 - val_accuracy: 0.9111\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3663 - accuracy: 0.8486 - val_loss: 0.3218 - val_accuracy: 0.9056\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3362 - accuracy: 0.8611 - val_loss: 0.3111 - val_accuracy: 0.8667\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3326 - accuracy: 0.8569 - val_loss: 0.2902 - val_accuracy: 0.9056\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 4ms/step - loss: 0.3280 - accuracy: 0.8708 - val_loss: 0.3341 - val_accuracy: 0.8611\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 5ms/step - loss: 0.3417 - accuracy: 0.8569 - val_loss: 0.2842 - val_accuracy: 0.8889\n",
      "6/6 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "model_history=model.fit(x=X_train, y=y_train, epochs=100, batch_size=32,validation_data= (X_test,y_test))\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90        97\n",
      "           1       0.90      0.86      0.88        83\n",
      "\n",
      "    accuracy                           0.89       180\n",
      "   macro avg       0.89      0.89      0.89       180\n",
      "weighted avg       0.89      0.89      0.89       180\n",
      "\n",
      "[[89  8]\n",
      " [12 71]]\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the predicted values\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test_class,y_pred_class))\n",
    "print(confusion_matrix(y_test_class,y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
